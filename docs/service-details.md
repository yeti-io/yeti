# üìã –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞

## –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
1. [Filtering Service](#filtering-service-–¥–µ—Ç–∞–ª—å–Ω–æ)
2. [Deduplication Service](#deduplication-service-–¥–µ—Ç–∞–ª—å–Ω–æ)
3. [Enrichment Service](#enrichment-service-–¥–µ—Ç–∞–ª—å–Ω–æ)
4. [Management Service](#management-service-–¥–µ—Ç–∞–ª—å–Ω–æ)

---

## Filtering Service (–î–µ—Ç–∞–ª—å–Ω–æ)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ —Ä–æ–ª—å
–ü–µ—Ä–≤—ã–π —ç—Ç–∞–ø pipeline - –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –≤—Ö–æ–¥—è—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞–±–æ—Ä—É –ø—Ä–∞–≤–∏–ª. –¢–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è, –ø—Ä–æ—à–µ–¥—à–∏–µ –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø.

### –û—Å–Ω–æ–≤–Ω–æ–π flow

```
Input Message
    ‚Üì
Read from: input_events queue
    ‚Üì
Load Rules Cache (RWMutex protected)
    ‚Üì
For each rule in cache:
  ‚îú‚îÄ Extract field from message
  ‚îú‚îÄ Apply operator
  ‚îú‚îÄ Check result
  ‚îî‚îÄ If any rule fails ‚Üí FILTER OUT
    ‚Üì
If all rules passed:
  ‚îú‚îÄ Add metadata: filters_applied
  ‚îú‚îÄ Publish to: dedup_events queue
  ‚îî‚îÄ Increment: messages_passed metric
    ‚Üì
If any rule failed:
  ‚îú‚îÄ Increment: messages_filtered metric
  ‚îú‚îÄ Log: debug with rule_id that filtered
  ‚îî‚îÄ Message dropped
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞

```go
// internal/filtering/models.go
type Rule struct {
    ID        string      `db:"id"`           // UUID
    Name      string      `db:"name"`         // User-friendly name
    Field     string      `db:"field"`        // Message field name
    Operator  string      `db:"operator"`     // eq, contains, regex, gt, lt, in, range
    Value     interface{} `db:"value"`        // Rule value
    Priority  int         `db:"priority"`     // Execution order
    Enabled   bool        `db:"enabled"`      // Is rule active
    CreatedAt time.Time   `db:"created_at"`
    UpdatedAt time.Time   `db:"updated_at"`
    Version   int         `db:"version"`      // For optimistic locking
}

type CompiledRule struct {
    Rule      Rule
    Regex     *regexp.Regexp  // Compiled regex if operator = regex
    Compiled  bool            // Is compiled successfully
}

type FilteringService struct {
    repo       Repository              // DB access
    metrics    *metrics.Metrics        // Prometheus metrics
    rules      map[string]*CompiledRule // In-memory cache
    rulesMu    sync.RWMutex           // Thread-safe access
    logger     logger.Logger
}

type Message map[string]interface{}
```

### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã

```go
// Process –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å–æ–æ–±—â–µ–Ω–∏—è
func (fs *FilteringService) Process(ctx context.Context, msg Message) (bool, error)
// Returns: (passed, error)

// GetRules –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
func (fs *FilteringService) GetRules() []Rule

// ReloadRules –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ –ë–î
func (fs *FilteringService) ReloadRules(ctx context.Context) error

// UpsertRule —Å–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–∞–≤–∏–ª–æ
func (fs *FilteringService) UpsertRule(ctx context.Context, rule Rule) error

// DeleteRule —É–¥–∞–ª—è–µ—Ç –ø—Ä–∞–≤–∏–ª–æ –ø–æ ID
func (fs *FilteringService) DeleteRule(ctx context.Context, ruleID string) error
```

### –û–ø–µ—Ä–∞—Ç–æ—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

```
1. eq (equals)
   - –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏
   - field = "status", value = "active"
   - Message: {status: "active"} ‚Üí PASS
   - Message: {status: "inactive"} ‚Üí FAIL

2. contains
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏
   - field = "email", value = "@example.com"
   - Message: {email: "user@example.com"} ‚Üí PASS

3. regex
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º
   - field = "email", value = "^[a-zA-Z0-9._%+-]+@..."
   - Regex –∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–∞–≤–∏–ª–∞
   - –û—à–∏–±–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è, –ø—Ä–∞–≤–∏–ª–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è

4. gt (greater than)
   - –ë–æ–ª—å—à–µ (–¥–ª—è —á–∏—Å–µ–ª)
   - field = "amount", value = 100
   - Message: {amount: 150} ‚Üí PASS
   - Message: {amount: 50} ‚Üí FAIL

5. lt (less than)
   - –ú–µ–Ω—å—à–µ (–¥–ª—è —á–∏—Å–µ–ª)
   - field = "age", value = 18
   - Message: {age: 16} ‚Üí PASS

6. in (in list)
   - –ó–Ω–∞—á–µ–Ω–∏–µ –≤ —Å–ø–∏—Å–∫–µ
   - field = "status", value = ["active", "pending"]
   - Message: {status: "active"} ‚Üí PASS
   - Message: {status: "deleted"} ‚Üí FAIL

7. range
   - –ó–Ω–∞—á–µ–Ω–∏–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [min, max]
   - field = "amount", value = [10, 1000]
   - Message: {amount: 500} ‚Üí PASS
   - Message: {amount: 5} ‚Üí FAIL
   - Message: {amount: 2000} ‚Üí FAIL
```

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```
Scenario: Missing field in message
‚îú‚îÄ config: on_missing_field = "filter_out"
‚îú‚îÄ Action: Return false (message filtered)
‚îî‚îÄ Metric: filtered_messages++

Scenario: Type mismatch (field is string, operator expects number)
‚îú‚îÄ config: on_type_mismatch = "filter_out"
‚îú‚îÄ Action: Return false
‚îî‚îÄ Metric: filtered_messages++

Scenario: Regex compilation error
‚îú‚îÄ Action: Log error, skip rule
‚îú‚îÄ Next rules: Still applied
‚îî‚îÄ Metric: errors++

Scenario: Database error while loading rules
‚îú‚îÄ Action: Keep existing rules in cache
‚îú‚îÄ Log: error with retry info
‚îî‚îÄ Retry: Exponential backoff 1s, 2s, 4s (max 3)
```

### Hot reload –º–µ—Ö–∞–Ω–∏–∑–º

```
Method 1: SIGHUP Signal
‚îú‚îÄ System receives SIGHUP
‚îú‚îÄ Handler: ReloadRules()
‚îú‚îÄ Load from PostgreSQL
‚îú‚îÄ Acquire RWMutex write lock
‚îú‚îÄ Replace fs.rules map
‚îú‚îÄ Release lock
‚îî‚îÄ New messages use new rules

Method 2: Polling (every 60 seconds)
‚îú‚îÄ Background goroutine
‚îú‚îÄ Query PostgreSQL for updated_at > last_check
‚îú‚îÄ If any rules updated
‚îú‚îÄ Call ReloadRules()
‚îî‚îÄ Continue polling

Method 3: Event-driven (via RabbitMQ)
‚îú‚îÄ Subscribe to: config.updates exchange
‚îú‚îÄ On message: filtering.rules.updated
‚îú‚îÄ Call: ReloadRules()
‚îî‚îÄ Process updated rules
```

### Database Schema (PostgreSQL)

```sql
-- –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–∞–≤–∏–ª
CREATE TABLE filtering_rules (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL UNIQUE,
  field VARCHAR(255) NOT NULL,
  operator VARCHAR(50) NOT NULL CHECK (operator IN ('eq','contains','regex','gt','lt','in','range')),
  value JSONB NOT NULL,
  priority INTEGER DEFAULT 0,
  enabled BOOLEAN DEFAULT true,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  created_by VARCHAR(255),
  updated_by VARCHAR(255),
  version INTEGER DEFAULT 1 -- Optimistic locking
);

-- –ò–Ω–¥–µ–∫—Å—ã
CREATE INDEX idx_filtering_rules_enabled ON filtering_rules(enabled);
CREATE INDEX idx_filtering_rules_priority ON filtering_rules(priority DESC);
CREATE INDEX idx_filtering_rules_updated_at ON filtering_rules(updated_at DESC);

-- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª (optional)
CREATE TABLE filtering_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  rule_id UUID REFERENCES filtering_rules(id),
  message_id VARCHAR(255) NOT NULL,
  matched BOOLEAN NOT NULL,
  processing_time_ms INTEGER,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_filtering_logs_created_at ON filtering_logs(created_at DESC);
```

### Metrics (Prometheus)

```
filtering_messages_total{status="passed|filtered|error"}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π

filtering_messages_duration_ms{status="passed|filtered"}
‚îú‚îÄ –¢–∏–ø: Histogram
‚îú‚îÄ Buckets: [1, 5, 10, 50, 100, 500, 1000]
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –º—Å

filtering_rules_total{enabled="true|false"}
‚îú‚îÄ –¢–∏–ø: Gauge
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Å–µ–≥–æ –ø—Ä–∞–≤–∏–ª (–∞–∫—Ç–∏–≤–Ω—ã—Ö/–Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö)

filtering_cache_size_bytes
‚îú‚îÄ –¢–∏–ø: Gauge
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –†–∞–∑–º–µ—Ä –∫–µ—à–∞ –ø—Ä–∞–≤–∏–ª –≤ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏

filtering_rule_evaluations_total{rule_id="..."}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–∞–≤–∏–ª–æ –±—ã–ª–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ

filtering_rule_matches_total{rule_id="..."}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–∞–≤–∏–ª–æ –ø—Ä–æ—à–ª–æ (match=true)
```

### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```go
// cmd/filtering-service/main.go
package main

import (
    "context"
    "data-pipeline/internal/filtering"
    "data-pipeline/internal/config"
    "data-pipeline/internal/logger"
    "data-pipeline/internal/storage"
)

func main() {
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    log := logger.New("filtering-service")
    cfg := config.Load("config.base.yaml")
    
    // –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    db := storage.NewPostgres(cfg.Database.Postgres)
    defer db.Close()
    
    // Metrics
    metrics := metrics.New()
    
    // –°–µ—Ä–≤–∏—Å
    repo := filtering.NewRepository(db)
    service := filtering.NewService(repo, metrics, log)
    
    // Hot reload –Ω–∞ SIGHUP
    config.WatchAndReload("config", service.ReloadRules)
    
    // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ broker
    consumer := broker.NewConsumer(cfg.Broker)
    producer := broker.NewProducer(cfg.Broker)
    
    msgChan, _ := consumer.Consume("input_events")
    
    for msg := range msgChan {
        ctx := context.Background()
        
        // –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        passed, err := service.Process(ctx, msg)
        
        if err != nil {
            log.Errorf("Filtering error: %v", err)
            continue
        }
        
        if passed {
            // –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            msg["filters_applied"] = map[string]interface{}{
                "passed_at": time.Now(),
            }
            
            // –û—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–∞–ª—å—à–µ
            producer.Publish("dedup_events", msg)
        }
    }
}
```

---

## Deduplication Service (–î–µ—Ç–∞–ª—å–Ω–æ)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ —Ä–æ–ª—å
–í—Ç–æ—Ä–æ–π —ç—Ç–∞–ø pipeline - –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Redis –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º –≤—Ä–µ–º–µ–Ω–Ω—ã–º –æ–∫–Ω–æ–º.

### –û—Å–Ω–æ–≤–Ω–æ–π flow

```
Input Message (—Å filters_applied)
    ‚Üì
Read from: dedup_events queue
    ‚Üì
Extract fields for hashing:
‚îú‚îÄ id
‚îú‚îÄ timestamp
‚îî‚îÄ source
    ‚Üì
Compute hash:
‚îî‚îÄ hash = md5(id + timestamp + source)
    ‚Üì
Check Redis:
‚îú‚îÄ SET key dedup:{hash}
‚îú‚îÄ With EX (expire) = 3600 (1 hour)
‚îú‚îÄ If SET successful ‚Üí UNIQUE
‚îî‚îÄ If SET returns nil ‚Üí DUPLICATE
    ‚Üì
If unique:
‚îú‚îÄ Add metadata: deduplication.is_unique = true
‚îú‚îÄ Publish to: enrichment_events queue
‚îî‚îÄ Increment: dedup_unique_messages metric
    ‚Üì
If duplicate:
‚îú‚îÄ Add metadata: deduplication.is_unique = false
‚îú‚îÄ Optional: Send to DLQ
‚îî‚îÄ Increment: dedup_duplicate_messages metric
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞

```go
// internal/deduplication/models.go
type HashConfig struct {
    Algorithm string   `yaml:"algorithm"` // md5, sha256
    Fields    []string `yaml:"fields"`    // Fields for hash
}

type DeduplicationService struct {
    redis        *redis.Client
    window       time.Duration
    hashConfig   HashConfig
    metrics      *metrics.Metrics
    logger       logger.Logger
    
    // Statistics
    stats struct {
        mu        sync.RWMutex
        unique    int64
        duplicate int64
        errors    int64
    }
}

type Message map[string]interface{}
```

### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã

```go
// Process –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
func (ds *DeduplicationService) Process(ctx context.Context, msg Message) (bool, error)
// Returns: (isUnique, error)

// UpdateWindow –æ–±–Ω–æ–≤–ª—è–µ—Ç –æ–∫–Ω–æ –¥–µ–¥—É–±–ª–∏–∫–∞—Ü–∏–∏ (hot reload)
func (ds *DeduplicationService) UpdateWindow(ctx context.Context, window time.Duration) error

// GetStats –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–µ–¥—É–±–ª–∏–∫–∞—Ü–∏–∏
func (ds *DeduplicationService) GetStats() DeduplicationStats

// ClearCache –æ—á–∏—â–∞–µ—Ç Redis (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
func (ds *DeduplicationService) ClearCache(ctx context.Context) error

// ComputeHash –≤—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Å–æ–æ–±—â–µ–Ω–∏—è
func (ds *DeduplicationService) ComputeHash(msg Message) (string, error)
```

### –ê–ª–≥–æ—Ä–∏—Ç–º —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è

```go
// –ü—Ä–∏–º–µ—Ä –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö–µ—à–∞
func (ds *DeduplicationService) ComputeHash(msg Message) (string, error) {
    // –î–æ—Å—Ç–∞–µ–º –ø–æ–ª—è
    id := msg["id"]
    timestamp := msg["timestamp"]
    source := msg["source"]
    
    // –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è —Ö–µ—à–∞
    hashInput := fmt.Sprintf("%v%v%v", id, timestamp, source)
    
    var hash string
    switch ds.hashConfig.Algorithm {
    case "md5":
        hash = fmt.Sprintf("%x", md5.Sum([]byte(hashInput)))
    case "sha256":
        hash = fmt.Sprintf("%x", sha256.Sum256([]byte(hashInput)))
    }
    
    return fmt.Sprintf("dedup:%s", hash), nil
}

// Redis –æ–ø–µ—Ä–∞—Ü–∏—è
// SET dedup:abc123def456 1734268500 EX 3600
// EX 3600 = expire –≤ 3600 —Å–µ–∫—É–Ω–¥ (1 —á–∞—Å)
```

### Redis Schema

```
Key Pattern:        dedup:{hash}
Value:              Timestamp (Unix format)
TTL:                Configurable (default: 3600 sec)
Eviction Policy:    allkeys-lru (least recently used)

Examples:
Key:    dedup:a1b2c3d4e5f6g7h8
Value:  1734268500
TTL:    3599 (expires in 3599 seconds)

Key:    dedup:z9y8x7w6v5u4t3s2
Value:  1734268450
TTL:    3600
```

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```
Scenario: Redis connection timeout
‚îú‚îÄ Max retries: 3
‚îú‚îÄ Backoff: exponential (100ms, 200ms, 400ms)
‚îú‚îÄ After max retries: send to DLQ
‚îî‚îÄ Log: error with traceback

Scenario: Invalid message (missing id/timestamp)
‚îú‚îÄ Action: Log warning
‚îú‚îÄ Behavior: Allow message (config: on_invalid_message = "allow")
‚îî‚îÄ Metric: errors++

Scenario: Hash computation fails
‚îú‚îÄ Action: Log error
‚îú‚îÄ Behavior: Send to DLQ (config: error_handling = "send_dlq")
‚îî‚îÄ Manual review required

Scenario: Redis key eviction (window expired naturally)
‚îú‚îÄ Action: None needed
‚îú‚îÄ Behavior: Message treated as unique if seen again
‚îú‚îÄ Reason: Window expired, duplicate check not relevant
‚îî‚îÄ This is expected behavior
```

### Hot reload –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

```
ConfigUpdate: {
  "window_seconds": 7200,  // –ò–∑–º–µ–Ω–∏–ª–∏ —Å 3600 –Ω–∞ 7200
  "hash_algorithm": "sha256"
}

Flow:
1. Management API: PUT /api/v1/config/deduplication
2. Update: ds.window = 7200 seconds
3. Update: ds.hashConfig.Algorithm = "sha256"
4. New messages: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –∏ –æ–∫–Ω–æ
5. Old messages: –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å—Ç–∞—Ä–æ–µ –æ–∫–Ω–æ (TTL –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–æ)
```

### Database Schema (Redis)

```
Redis —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—Ö–µ–º—ã,
–æ–¥–Ω–∞–∫–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É:

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:
- dedup:stats:unique_messages (counter)
- dedup:stats:duplicate_messages (counter)
- dedup:stats:errors (counter)
- dedup:stats:cache_hits (counter)
- dedup:stats:cache_misses (counter)

–û–±–Ω–æ–≤–ª—è—é—Ç—Å—è –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É —á–µ—Ä–µ–∑ background goroutine.
```

### Metrics (Prometheus)

```
dedup_messages_total{status="unique|duplicate|error"}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π

dedup_processing_duration_ms
‚îú‚îÄ –¢–∏–ø: Histogram
‚îú‚îÄ Buckets: [1, 5, 10, 50, 100, 500]
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏ Redis

dedup_cache_hit_rate
‚îú‚îÄ –¢–∏–ø: Gauge
‚îú‚îÄ Range: [0.0, 1.0]
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–æ–ø–∞–¥–∞–Ω–∏–π –∫ –ø—Ä–æ–º–∞—Ö–∞–º

dedup_window_duration_seconds
‚îú‚îÄ –¢–∏–ø: Gauge
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –¢–µ–∫—É—â–µ–µ –æ–∫–Ω–æ –¥–µ–¥—É–±–ª–∏–∫–∞—Ü–∏–∏

dedup_redis_errors_total
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –û—à–∏–±–∫–∏ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Redis

dedup_cache_size_bytes
‚îú‚îÄ –¢–∏–ø: Gauge
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –ü—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–µ—à–∞ (–µ—Å–ª–∏ tracked)
```

### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```go
// cmd/dedup-service/main.go
package main

func main() {
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    log := logger.New("dedup-service")
    cfg := config.Load("config.base.yaml")
    
    // Redis
    redisClient := storage.NewRedis(cfg.Database.Redis)
    defer redisClient.Close()
    
    // Metrics
    metrics := metrics.New()
    
    // –°–µ—Ä–≤–∏—Å
    service := deduplication.New(
        redisClient,
        cfg.Deduplication.Window,
        cfg.Deduplication.HashConfig,
        metrics,
        log,
    )
    
    // Hot reload –∫–æ–Ω—Ñ–∏–≥–∞
    config.WatchAndReload("config", func() {
        newCfg := config.Load("config.base.yaml")
        service.UpdateWindow(context.Background(), newCfg.Deduplication.Window)
    })
    
    // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
    consumer := broker.NewConsumer(cfg.Broker)
    producer := broker.NewProducer(cfg.Broker)
    
    msgChan, _ := consumer.Consume("dedup_events")
    
    for msg := range msgChan {
        ctx := context.Background()
        
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–¥—É–±–ª–∏–∫–∞—Ü–∏–∏
        isUnique, err := service.Process(ctx, msg)
        
        if err != nil {
            log.Errorf("Dedup error: %v", err)
            // –û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ DLQ
            continue
        }
        
        if isUnique {
            // –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            msg["deduplication"] = map[string]interface{}{
                "is_unique": true,
                "checked_at": time.Now(),
            }
            
            // –û—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–∞–ª—å—à–µ
            producer.Publish("enrichment_events", msg)
        } else {
            // –î—É–±–ª–∏–∫–∞—Ç - –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–ª—å—à–µ
            log.Debug("Duplicate message filtered", "message_id", msg["id"])
        }
    }
}
```

---

## Enrichment Service (–î–µ—Ç–∞–ª—å–Ω–æ)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ —Ä–æ–ª—å
–¢—Ä–µ—Ç–∏–π —ç—Ç–∞–ø pipeline - –æ–±–æ–≥–∞—â–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (API, –ë–î, –∫–µ—à). –ù–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç pipeline –µ—Å–ª–∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å.

### –û—Å–Ω–æ–≤–Ω–æ–π flow

```
Input Message (—Å filters_applied + deduplication)
    ‚Üì
Read from: enrichment_events queue
    ‚Üì
Load Enrichment Rules from MongoDB
    ‚Üì
For each rule (in priority order):
    ‚îú‚îÄ Extract required field from message
    ‚îú‚îÄ Determine source type
    ‚îú‚îÄ Check Cache (Redis)
    ‚îÇ   ‚îú‚îÄ If hit: use cached data
    ‚îÇ   ‚îî‚îÄ If miss: fetch from source
    ‚îú‚îÄ Fetch data:
    ‚îÇ   ‚îú‚îÄ If API: HTTP call with timeout
    ‚îÇ   ‚îú‚îÄ If DB: MongoDB/PostgreSQL query
    ‚îÇ   ‚îú‚îÄ If Cache: Redis get
    ‚îÇ   ‚îî‚îÄ If File: Load from disk
    ‚îú‚îÄ Transform data (if rules exist)
    ‚îú‚îÄ Merge with message
    ‚îú‚îÄ Cache result (with TTL)
    ‚îî‚îÄ Continue to next rule (even if failed)
    ‚Üì
Add enrichment metadata
    ‚îú‚îÄ rules_applied: [list of rule IDs]
    ‚îú‚îÄ enriched_at: timestamp
    ‚îî‚îÄ cache_hits: count
    ‚Üì
Publish to: processed_events queue
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞

```go
// internal/enrichment/models.go
type EnrichmentRule struct {
    ID                    string      `bson:"_id,omitempty"`
    Name                  string      `bson:"name"`
    FieldToEnrich         string      `bson:"field_to_enrich"`
    SourceType            string      `bson:"source_type"` // api, database, cache, file
    SourceConfig          SourceConfig
    TransformationRules   []Transformation
    CacheTTLSeconds       int
    ErrorHandling         string      // skip_field, skip_rule, fail
    FallbackValue         interface{}
    Priority              int
    Enabled               bool
    CreatedAt             time.Time
    UpdatedAt             time.Time
}

type SourceConfig struct {
    // API source
    URL             string
    Method          string
    TimeoutMs       int
    RetryCount      int
    Headers         map[string]string
    
    // Database source
    Database        string
    Collection      string
    Query           map[string]interface{}
    Projection      map[string]interface{}
    Limit           int
    
    // Cache source
    KeyPattern      string
    CacheType       string // redis, memcached
    
    // File source
    FilePath        string
    Format          string // json, yaml, csv
}

type Transformation struct {
    SourcePath  string      // JSON path in response
    TargetField string      // Field in message
    Transform   string      // identity, upper, lower, json_parse
    Default     interface{} // Fallback value if source missing
}

type EnrichmentService struct {
    rules         map[string]*EnrichmentRule
    rulesMu       sync.RWMutex
    providers     map[string]DataProvider  // API, DB, Cache providers
    cache         *redis.Client
    metrics       *metrics.Metrics
    logger        logger.Logger
}

type DataProvider interface {
    Fetch(ctx context.Context, config SourceConfig, fieldValue interface{}) (interface{}, error)
}
```

### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã

```go
// Process –æ–±–æ–≥–∞—â–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ
func (es *EnrichmentService) Process(ctx context.Context, msg Message) (*Message, error)
// Returns: (*enrichedMessage, error)

// GetRules –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
func (es *EnrichmentService) GetRules() []EnrichmentRule

// ReloadRules –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ MongoDB
func (es *EnrichmentService) ReloadRules(ctx context.Context) error

// UpsertRule —Å–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–∞–≤–∏–ª–æ
func (es *EnrichmentService) UpsertRule(ctx context.Context, rule EnrichmentRule) error

// FetchData –ø–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Å –∫–µ—à–µ–º
func (es *EnrichmentService) FetchData(ctx context.Context, rule EnrichmentRule, fieldValue interface{}) (interface{}, error)

// ClearCache –æ—á–∏—â–∞–µ—Ç –∫–µ—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±–æ–≥–∞—â–µ–Ω–∏—è
func (es *EnrichmentService) ClearCache(ctx context.Context) error
```

### Data Providers

```go
// 1. API Provider
type APIProvider struct {
    httpClient *http.Client
}

func (p *APIProvider) Fetch(ctx context.Context, config SourceConfig, fieldValue interface{}) (interface{}, error) {
    // –ó–∞–º–µ–Ω—è–µ–º {field_name} –≤ URL –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏–µ
    // –ü—Ä–∏–º–µ—Ä: "https://api/users/{user_id}" + user_id="123" ‚Üí "https://api/users/123"
    url := strings.ReplaceAll(config.URL, "{field_value}", fmt.Sprintf("%v", fieldValue))
    
    // HTTP –∑–∞–ø—Ä–æ—Å —Å timeout
    req, _ := http.NewRequestWithContext(ctx, config.Method, url, nil)
    req.Header = http.Header(config.Headers)
    
    resp, err := p.httpClient.Do(req)
    // Parse response JSON
    // Return data
}

// 2. Database Provider
type DatabaseProvider struct {
    mongoClient *mongo.Client
    postgresDB  *sql.DB
}

func (p *DatabaseProvider) Fetch(ctx context.Context, config SourceConfig, fieldValue interface{}) (interface{}, error) {
    // Replace placeholders in query
    query := replaceQueryPlaceholders(config.Query, fieldValue)
    
    // Execute query
    // Return result
}

// 3. Cache Provider
type CacheProvider struct {
    redisClient *redis.Client
}

func (p *CacheProvider) Fetch(ctx context.Context, config SourceConfig, fieldValue interface{}) (interface{}, error) {
    // Build key from pattern
    key := strings.ReplaceAll(config.KeyPattern, "{value}", fmt.Sprintf("%v", fieldValue))
    
    // Get from Redis
    data, err := p.redisClient.Get(ctx, key).Result()
    // Return parsed data
}

// 4. File Provider
type FileProvider struct{}

func (p *FileProvider) Fetch(ctx context.Context, config SourceConfig, fieldValue interface{}) (interface{}, error) {
    // Load file (cached in memory)
    // Search for entry matching fieldValue
    // Return entry
}
```

### –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```
–ö–ª—é—á –∫–µ—à–∞:       enrich:{rule_id}:{field_value_hash}
–ó–Ω–∞—á–µ–Ω–∏–µ:        JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–æ–≥–∞—â–µ–Ω–∏—è
TTL:             –ò–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –ø—Ä–∞–≤–∏–ª–∞ (default: 1800 sec)

–ü—Ä–∏–º–µ—Ä:
–ü—Ä–∞–≤–∏–ª–æ: enrich-user-profile
Field:   user_id = "user-789"

Cache Key:   enrich:enrich-user-profile:abc123def456
Cache Value: {
  "name": "John Doe",
  "account_age_days": 365,
  "lifetime_value": 5000.00
}
TTL:         1800 seconds

–ü—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –æ–±–æ–≥–∞—â–µ–Ω–∏–∏ —Ç–æ–≥–æ –∂–µ user_id:
- –ü–æ–ª—É—á–∏—Ç—å –∏–∑ –∫–µ—à–∞ (1-5 –º—Å –≤–º–µ—Å—Ç–æ 50-100 –º—Å –Ω–∞ API)
- –û–±–Ω–æ–≤–∏—Ç—å –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏
- –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É cache_hits
```

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```
Scenario: API timeout
‚îú‚îÄ Retry: 3 —Ä–∞–∑–∞ —Å exponential backoff
‚îú‚îÄ After retries: apply error_handling strategy
‚îú‚îÄ Strategy: skip_field ‚Üí –æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ–ª–µ –ø—É—Å—Ç—ã–º
‚îÇ ‚îÇ skip_rule ‚Üí –Ω–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
‚îÇ ‚îî fail ‚Üí –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ DLQ
‚îî‚îÄ Log: error —Å URL –∏ timeout info

Scenario: Database query fails
‚îú‚îÄ Action: Log error with query details
‚îú‚îÄ Apply: error_handling strategy (skip_field default)
‚îî‚îÄ Continue: pipeline –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è

Scenario: JSON parse fails
‚îú‚îÄ Action: Log error with JSON sample
‚îú‚îÄ Apply: fallback_value (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω)
‚îî‚îÄ Continue: pipeline –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è

Scenario: Cache miss + API failure
‚îú‚îÄ Action: Check fallback_value
‚îú‚îÄ If exists: use fallback
‚îú‚îÄ If not: skip enrichment
‚îî‚îÄ Continue: pipeline –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è
```

### Transformation Functions

```
identity:      Return value as-is
upper:         Convert to uppercase string
lower:         Convert to lowercase string
to_int:        Parse to integer
to_float:      Parse to float
to_bool:       Parse to boolean
json_parse:    Parse JSON string to object
json_stringify: Convert object to JSON string
concat:        Concatenate multiple values
date_format:   Format date (supports custom patterns)
truncate:      Truncate string (max length)
trim:          Remove whitespace
replace:       Replace substring
split:         Split string to array
join:          Join array to string
```

### Database Schema (MongoDB)

```javascript
// –ö–æ–ª–ª–µ–∫—Ü–∏—è –ø—Ä–∞–≤–∏–ª –æ–±–æ–≥–∞—â–µ–Ω–∏—è
db.enrichment_rules.createCollection("enrichment_rules", {
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: ["name", "source_type", "enabled"],
      properties: {
        _id: { bsonType: "objectId" },
        name: { bsonType: "string" },
        field_to_enrich: { bsonType: "string" },
        source_type: { enum: ["api", "database", "cache", "file"] },
        source_config: { bsonType: "object" },
        transformation_rules: { bsonType: "array" },
        cache_ttl_seconds: { bsonType: "int" },
        error_handling: { enum: ["skip_field", "skip_rule", "fail"] },
        fallback_value: {},  // –õ—é–±–æ–π —Ç–∏–ø
        priority: { bsonType: "int" },
        enabled: { bsonType: "bool" },
        created_at: { bsonType: "date" },
        updated_at: { bsonType: "date" }
      }
    }
  }
});

// –ò–Ω–¥–µ–∫—Å—ã
db.enrichment_rules.createIndex({ "enabled": 1, "priority": 1 });
db.enrichment_rules.createIndex({ "updated_at": -1 });

// –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –∫–µ—à–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è
db.enrichment_cache.createCollection("enrichment_cache");

// TTL –∏–Ω–¥–µ–∫—Å (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ N —Å–µ–∫—É–Ω–¥)
db.enrichment_cache.createIndex(
  { "created_at": 1 },
  { expireAfterSeconds: 3600 }
);

// –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –∫–µ—à–µ:
{
  _id: ObjectId(),
  rule_id: "enrich-user-profile",
  field_value_hash: "abc123def456",
  data: { ... },
  created_at: ISODate("2025-12-14T14:55:00Z")
}
```

### Metrics (Prometheus)

```
enrichment_messages_total{status="processed|partial|error"}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π

enrichment_processing_duration_ms
‚îú‚îÄ –¢–∏–ø: Histogram
‚îú‚îÄ Buckets: [1, 5, 10, 50, 100, 200, 500, 1000, 2000]
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–≤–∫–ª—é—á–∞—è –≤—Å–µ API –≤—ã–∑–æ–≤—ã)

enrichment_cache_hit_rate
‚îú‚îÄ –¢–∏–ø: Gauge
‚îú‚îÄ Range: [0.0, 1.0]
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–æ–ø–∞–¥–∞–Ω–∏–π –∫–µ—à–∞

enrichment_rule_executions_total{rule_id="..."}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–∞–≤–∏–ª–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ

enrichment_rule_success_total{rule_id="..."}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–∞–≤–∏–ª–æ —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ

enrichment_api_calls_total{endpoint="..."}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Å–µ–≥–æ API –≤—ã–∑–æ–≤–æ–≤

enrichment_api_errors_total{endpoint="..."}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: API –æ—à–∏–±–∫–∏

enrichment_api_latency_ms{endpoint="..."}
‚îú‚îÄ –¢–∏–ø: Histogram
‚îú‚îÄ Buckets: [10, 50, 100, 500, 1000, 2000, 5000]
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –õ–∞—Ç–µ–Ω—Ü–∏—è API –≤—ã–∑–æ–≤–æ–≤
```

### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```go
// cmd/enrichment-service/main.go
package main

func main() {
    log := logger.New("enrichment-service")
    cfg := config.Load("config.base.yaml")
    
    // MongoDB –¥–ª—è –ø—Ä–∞–≤–∏–ª
    mongoClient := storage.NewMongoDB(cfg.Database.MongoDB)
    defer mongoClient.Disconnect(context.Background())
    
    // Redis –¥–ª—è –∫–µ—à–∞
    redisClient := storage.NewRedis(cfg.Database.Redis)
    defer redisClient.Close()
    
    // Metrics
    metrics := metrics.New()
    
    // –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
    providers := map[string]enrichment.DataProvider{
        "api":      enrichment.NewAPIProvider(),
        "database": enrichment.NewDatabaseProvider(mongoClient),
        "cache":    enrichment.NewCacheProvider(redisClient),
        "file":     enrichment.NewFileProvider(),
    }
    
    // –°–µ—Ä–≤–∏—Å –æ–±–æ–≥–∞—â–µ–Ω–∏—è
    service := enrichment.New(
        mongoClient,
        redisClient,
        providers,
        metrics,
        log,
    )
    
    // Hot reload –ø—Ä–∞–≤–∏–ª
    config.WatchAndReload("config", func() {
        if err := service.ReloadRules(context.Background()); err != nil {
            log.Errorf("Failed to reload enrichment rules: %v", err)
        }
    })
    
    // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
    consumer := broker.NewConsumer(cfg.Broker)
    producer := broker.NewProducer(cfg.Broker)
    
    msgChan, _ := consumer.Consume("enrichment_events")
    
    for msg := range msgChan {
        ctx := context.Background()
        
        // –û–±–æ–≥–∞—â–µ–Ω–∏–µ
        enrichedMsg, err := service.Process(ctx, msg)
        
        if err != nil {
            log.Errorf("Enrichment error: %v", err)
            // –û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ DLQ –∏ continue
            continue
        }
        
        // –û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        producer.Publish("processed_events", enrichedMsg)
    }
}
```

---

## Management Service (–î–µ—Ç–∞–ª—å–Ω–æ)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ —Ä–æ–ª—å
REST API –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ–º–∏ –ø—Ä–∞–≤–∏–ª–∞–º–∏ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤. –ü–æ–∑–≤–æ–ª—è–µ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º –∏–∑–º–µ–Ω—è—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –≤ runtime –±–µ–∑ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏.

### –û—Å–Ω–æ–≤–Ω–æ–π flow

```
HTTP Request: POST /api/v1/rules/filtering
    ‚Üì
Validate request:
‚îú‚îÄ Authentication
‚îú‚îÄ Authorization (RBAC)
‚îú‚îÄ Rule validation
‚îî‚îÄ Business logic checks
    ‚Üì
If validation fails:
‚îî‚îÄ Return 400/401/403 —Å error details
    ‚Üì
If validation passes:
‚îú‚îÄ Begin transaction
‚îú‚îÄ Insert into PostgreSQL
‚îú‚îÄ Create version entry
‚îú‚îÄ Create audit log entry
‚îú‚îÄ Commit transaction
‚îú‚îÄ If transaction fails: rollback + return 500
    ‚Üì
Notify services:
‚îú‚îÄ Send message to RabbitMQ: config.updates
‚îú‚îÄ Or HTTP webhook (if configured)
    ‚Üì
Cache invalidation:
‚îî‚îÄ Clear HTTP response cache
    ‚Üì
Return 201 Created —Å —Å–æ–∑–¥–∞–Ω–Ω—ã–º –ø—Ä–∞–≤–∏–ª–æ–º
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞

```go
// internal/management/models.go
type CreateRuleRequest struct {
    Name  string      `json:"name" binding:"required"`
    Field string      `json:"field" binding:"required"`
    // ... other fields
}

type UpdateRuleRequest struct {
    Name     string      `json:"name"`
    Value    interface{} `json:"value"`
    Enabled  *bool       `json:"enabled"`
    Priority *int        `json:"priority"`
    // ... other optional fields
}

type RuleResponse struct {
    ID        string      `json:"id"`
    Name      string      `json:"name"`
    CreatedAt time.Time   `json:"created_at"`
    UpdatedAt time.Time   `json:"updated_at"`
    Version   int         `json:"version"`
    // ... other fields
}

type ManagementService struct {
    filteringRepo    FilteringRepository
    dedupRepo        DedupRepository
    enrichmentRepo   EnrichmentRepository
    notifier         Notifier
    validator        RuleValidator
    metrics          *metrics.Metrics
    logger           logger.Logger
}

type Notifier interface {
    NotifyRuleCreated(ctx context.Context, rule interface{}) error
    NotifyRuleUpdated(ctx context.Context, rule interface{}) error
    NotifyRuleDeleted(ctx context.Context, ruleID string) error
}
```

### REST API Endpoints (–ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫)

```
=== FILTERING RULES ===
GET     /api/v1/rules/filtering
        –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–∞–≤–∏–ª —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        Params: enabled=true|false, page=1, limit=20
        Response: List[Rule]

POST    /api/v1/rules/filtering
        –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –ø—Ä–∞–≤–∏–ª–æ
        Body: CreateRuleRequest
        Response: 201 Created, Rule

GET     /api/v1/rules/filtering/:id
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ –ø–æ ID
        Response: Rule

PUT     /api/v1/rules/filtering/:id
        –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ
        Body: UpdateRuleRequest
        Response: 200 OK, Rule

DELETE  /api/v1/rules/filtering/:id
        –£–¥–∞–ª–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ
        Response: 204 No Content

PATCH   /api/v1/rules/filtering/:id/toggle
        –í–∫–ª—é—á–∏—Ç—å/–æ—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ
        Body: { "enabled": true|false }
        Response: 200 OK, Rule

GET     /api/v1/rules/filtering/:id/audit
        –ò—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø—Ä–∞–≤–∏–ª–∞
        Response: List[AuditLog]

=== DEDUPLICATION CONFIG ===
GET     /api/v1/config/deduplication
        –¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–µ–¥—É–±–ª–∏–∫–∞—Ü–∏–∏
        Response: DeduplicationConfig

PUT     /api/v1/config/deduplication
        –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        Body: UpdateDedupConfigRequest
        Response: 200 OK, DeduplicationConfig

GET     /api/v1/stats/deduplication
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–µ–¥—É–±–ª–∏–∫–∞—Ü–∏–∏
        Response: DedupStats

=== ENRICHMENT RULES ===
GET     /api/v1/rules/enrichment
        –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–∞–≤–∏–ª –æ–±–æ–≥–∞—â–µ–Ω–∏—è
        Response: List[EnrichmentRule]

POST    /api/v1/rules/enrichment
        –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –ø—Ä–∞–≤–∏–ª–æ
        Body: CreateEnrichmentRuleRequest
        Response: 201 Created, EnrichmentRule

GET     /api/v1/rules/enrichment/:id
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ –ø–æ ID
        Response: EnrichmentRule

PUT     /api/v1/rules/enrichment/:id
        –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ
        Body: UpdateEnrichmentRuleRequest
        Response: 200 OK, EnrichmentRule

DELETE  /api/v1/rules/enrichment/:id
        –£–¥–∞–ª–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ
        Response: 204 No Content

PATCH   /api/v1/rules/enrichment/:id/toggle
        –í–∫–ª—é—á–∏—Ç—å/–æ—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ
        Response: 200 OK, EnrichmentRule

=== HEALTH & STATS ===
GET     /api/v1/health
        Health check –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
        Response: HealthStatus

GET     /api/v1/stats
        –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ pipeline
        Response: PipelineStats

GET     /api/v1/stats/pipeline
        –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç—Ç–∞–ø–∞–º
        Response: DetailedPipelineStats

GET     /api/v1/metrics
        Prometheus –º–µ—Ç—Ä–∏–∫–∏
        Response: text/plain (Prometheus format)

=== CONFIGURATION MANAGEMENT ===
POST    /api/v1/rules/reload-signal
        –û—Ç–ø—Ä–∞–≤–∏—Ç—å SIGHUP —Å–∏–≥–Ω–∞–ª —Å–µ—Ä–≤–∏—Å–∞–º
        Query: service=filtering|dedup|enrichment|all
        Response: 200 OK, { "status": "signal_sent" }

GET     /api/v1/config/services
        –°—Ç–∞—Ç—É—Å –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
        Response: { services: [ServiceStatus] }
```

### –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∞–≤–∏–ª

```go
// Filtering Rule Validation
type FilteringRuleValidator struct{}

func (v *FilteringRuleValidator) Validate(rule Rule) error {
    if rule.Field == "" {
        return errors.New("field is required")
    }
    
    validOperators := []string{"eq", "contains", "regex", "gt", "lt", "in", "range"}
    if !contains(validOperators, rule.Operator) {
        return fmt.Errorf("invalid operator: %s", rule.Operator)
    }
    
    if rule.Value == nil {
        return errors.New("value is required")
    }
    
    // Type validation based on operator
    switch rule.Operator {
    case "gt", "lt":
        if _, ok := toFloat(rule.Value); !ok {
            return errors.New("value must be numeric for gt/lt operators")
        }
    case "regex":
        if _, err := regexp.Compile(rule.Value.(string)); err != nil {
            return fmt.Errorf("invalid regex: %v", err)
        }
    case "in":
        if _, ok := rule.Value.([]interface{}); !ok {
            return errors.New("value must be array for in operator")
        }
    case "range":
        if arr, ok := rule.Value.([]interface{}); !ok || len(arr) != 2 {
            return errors.New("value must be array of 2 elements for range operator")
        }
    }
    
    return nil
}
```

### Request/Response –ø—Ä–∏–º–µ—Ä—ã

```http
--- CREATE FILTERING RULE ---
POST /api/v1/rules/filtering
Content-Type: application/json
Authorization: Bearer eyJ0eXAi...

{
  "name": "Premium users only",
  "field": "subscription_tier",
  "operator": "eq",
  "value": "premium",
  "priority": 1,
  "enabled": true
}

Response 201 Created:
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "name": "Premium users only",
  "field": "subscription_tier",
  "operator": "eq",
  "value": "premium",
  "priority": 1,
  "enabled": true,
  "created_at": "2025-12-14T14:55:00Z",
  "updated_at": "2025-12-14T14:55:00Z",
  "version": 1,
  "created_by": "admin@example.com"
}

--- UPDATE ENRICHMENT RULE ---
PUT /api/v1/rules/enrichment/550e8400-e29b-41d4-a716-446655440001
Content-Type: application/json
Authorization: Bearer eyJ0eXAi...

{
  "source_config": {
    "url": "https://api.example.com/users/{user_id}",
    "timeout_ms": 8000,
    "retry_count": 5
  },
  "cache_ttl_seconds": 1800
}

Response 200 OK:
{
  "id": "550e8400-e29b-41d4-a716-446655440001",
  "name": "Enrich with user profile",
  "field_to_enrich": "user_id",
  "source_type": "api",
  "source_config": { ... },
  "cache_ttl_seconds": 1800,
  "version": 2,
  "updated_at": "2025-12-14T14:56:00Z",
  "updated_by": "admin@example.com"
}

--- GET PIPELINE STATS ---
GET /api/v1/stats/pipeline

Response 200 OK:
{
  "timestamp": "2025-12-14T14:56:00Z",
  "total_messages": 1000000,
  "filtering": {
    "input": 1000000,
    "passed": 850000,
    "filtered": 150000,
    "pass_rate": 0.85,
    "error_rate": 0.001,
    "avg_processing_ms": 2.5
  },
  "deduplication": {
    "input": 850000,
    "unique": 800000,
    "duplicate": 50000,
    "unique_rate": 0.941,
    "error_rate": 0.0,
    "avg_processing_ms": 1.2
  },
  "enrichment": {
    "input": 800000,
    "enriched": 790000,
    "partial": 10000,
    "error_rate": 0.002,
    "cache_hit_rate": 0.75,
    "avg_processing_ms": 45.3
  },
  "uptime_seconds": 86400
}
```

### Database Schema (PostgreSQL)

```sql
-- –¢–∞–±–ª–∏—Ü–∞ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª
CREATE TABLE rule_versions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  rule_id UUID NOT NULL,
  rule_type VARCHAR(50) NOT NULL,  -- filtering, enrichment, dedup
  rule_data JSONB NOT NULL,
  version INTEGER NOT NULL,
  changed_by VARCHAR(255),
  change_reason TEXT,
  created_at TIMESTAMP DEFAULT NOW(),
  UNIQUE(rule_id, version),
  FOREIGN KEY (rule_id) REFERENCES filtering_rules(id) ON DELETE CASCADE
);

-- –¢–∞–±–ª–∏—Ü–∞ –∞—É–¥–∏—Ç –ª–æ–≥–æ–≤
CREATE TABLE rule_audit_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  rule_id UUID,
  rule_type VARCHAR(50) NOT NULL,
  action VARCHAR(50) NOT NULL,  -- create, update, delete
  old_value JSONB,
  new_value JSONB,
  changed_by VARCHAR(255) NOT NULL,
  change_reason TEXT,
  timestamp TIMESTAMP DEFAULT NOW(),
  ip_address VARCHAR(45)
);

-- API access logs (optional)
CREATE TABLE api_access_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id VARCHAR(255),
  method VARCHAR(10),
  path VARCHAR(512),
  status_code INTEGER,
  response_time_ms INTEGER,
  request_id VARCHAR(255),
  timestamp TIMESTAMP DEFAULT NOW()
);

-- –ò–Ω–¥–µ–∫—Å—ã
CREATE INDEX idx_rule_versions_rule_id ON rule_versions(rule_id);
CREATE INDEX idx_rule_versions_created_at ON rule_versions(created_at DESC);
CREATE INDEX idx_audit_logs_rule_id ON rule_audit_logs(rule_id);
CREATE INDEX idx_audit_logs_timestamp ON rule_audit_logs(timestamp DESC);
CREATE INDEX idx_api_logs_user_id ON api_access_logs(user_id);
CREATE INDEX idx_api_logs_timestamp ON api_access_logs(timestamp DESC);
```

### –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–æ–≤

```go
// –°–ø–æ—Å–æ–± 1: RabbitMQ Event
type ConfigUpdateNotification struct {
    RuleID    string
    RuleType  string  // filtering, enrichment, dedup
    Action    string  // created, updated, deleted
    Timestamp time.Time
    ChangedBy string
}

// –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤ exchange: config.updates
// Routing key: {rule_type}.{action}
// –ü—Ä–∏–º–µ—Ä: filtering.updated, enrichment.created

// –°–ø–æ—Å–æ–± 2: HTTP Webhook
type WebhookPayload struct {
    Event       string
    Rule        interface{}
    Timestamp   time.Time
    SignedHash  string  // HMAC –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
}

// –°–µ—Ä–≤–∏—Å —Å–ª—É—à–∞–µ—Ç GET request –Ω–∞ configured webhook URL
// –ò –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç rules –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è
```

### Metrics (Prometheus)

```
management_api_requests_total{method="GET|POST|PUT|DELETE",path="..."}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Å–µ–≥–æ API –∑–∞–ø—Ä–æ—Å–æ–≤

management_api_response_time_ms{path="..."}
‚îú‚îÄ –¢–∏–ø: Histogram
‚îú‚îÄ Buckets: [1, 5, 10, 50, 100, 200, 500, 1000]
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ API

management_rules_total{type="filtering|enrichment"}
‚îú‚îÄ –¢–∏–ø: Gauge
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Å–µ–≥–æ –ø—Ä–∞–≤–∏–ª –ø–æ —Ç–∏–ø–∞–º

management_rule_changes_total{action="create|update|delete"}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –í—Å–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø—Ä–∞–≤–∏–ª

management_api_errors_total{status="400|401|403|500"}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –û—à–∏–±–∫–∏ API –ø–æ –∫–æ–¥–∞–º

management_database_transactions_total{status="commit|rollback"}
‚îú‚îÄ –¢–∏–ø: Counter
‚îî‚îÄ –û–ø–∏—Å–∞–Ω–∏–µ: –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –ë–î
```

---

